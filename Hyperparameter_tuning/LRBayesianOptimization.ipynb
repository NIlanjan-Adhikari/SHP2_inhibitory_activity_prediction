{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40156c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, \\\n",
    "  ConfusionMatrixDisplay, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce82414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxPartialCharge</th>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <th>BCUT2D_CHGLO</th>\n",
       "      <th>BCUT2D_MRHI</th>\n",
       "      <th>PEOE_VSA12</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>SMR_VSA3</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>SlogP_VSA8</th>\n",
       "      <th>EState_VSA6</th>\n",
       "      <th>NumHAcceptors</th>\n",
       "      <th>NumSaturatedCarbocycles</th>\n",
       "      <th>fr_bicyclic</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.335201</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>-2.072068</td>\n",
       "      <td>5.975550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>9.551078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.974594</td>\n",
       "      <td>43.638476</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.226791</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.362642</td>\n",
       "      <td>7.150190</td>\n",
       "      <td>5.948339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.967957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.440599</td>\n",
       "      <td>11.336786</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.211302</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>-2.089721</td>\n",
       "      <td>7.912349</td>\n",
       "      <td>9.837253</td>\n",
       "      <td>29.297126</td>\n",
       "      <td>4.983979</td>\n",
       "      <td>9.837253</td>\n",
       "      <td>10.902925</td>\n",
       "      <td>24.265468</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226898</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>-2.357502</td>\n",
       "      <td>6.433493</td>\n",
       "      <td>5.948339</td>\n",
       "      <td>35.334614</td>\n",
       "      <td>15.284746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.126903</td>\n",
       "      <td>12.263211</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158370</td>\n",
       "      <td>1.870968</td>\n",
       "      <td>-2.421374</td>\n",
       "      <td>7.991366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.362825</td>\n",
       "      <td>19.935914</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.460054</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>0.152613</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.415835</td>\n",
       "      <td>6.432407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.334614</td>\n",
       "      <td>9.967957</td>\n",
       "      <td>11.343745</td>\n",
       "      <td>11.257379</td>\n",
       "      <td>6.066367</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>0.335203</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>-2.001320</td>\n",
       "      <td>6.164147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.331835</td>\n",
       "      <td>4.983979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.902925</td>\n",
       "      <td>36.528679</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>0.264178</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>-2.414068</td>\n",
       "      <td>5.737009</td>\n",
       "      <td>5.948339</td>\n",
       "      <td>38.112943</td>\n",
       "      <td>9.551078</td>\n",
       "      <td>11.784535</td>\n",
       "      <td>11.126903</td>\n",
       "      <td>11.614772</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>0.338995</td>\n",
       "      <td>1.815789</td>\n",
       "      <td>-2.065301</td>\n",
       "      <td>7.218862</td>\n",
       "      <td>5.907180</td>\n",
       "      <td>59.014740</td>\n",
       "      <td>24.544948</td>\n",
       "      <td>18.386966</td>\n",
       "      <td>43.634305</td>\n",
       "      <td>6.196844</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>0.282757</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>-2.330174</td>\n",
       "      <td>9.102997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.147817</td>\n",
       "      <td>9.799819</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2739 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MaxPartialCharge  FpDensityMorgan2  BCUT2D_CHGLO  BCUT2D_MRHI  \\\n",
       "0             0.335201          1.714286     -2.072068     5.975550   \n",
       "1             0.226791          2.000000     -2.362642     7.150190   \n",
       "2             0.211302          1.772727     -2.089721     7.912349   \n",
       "3             0.226898          1.869565     -2.357502     6.433493   \n",
       "4             0.158370          1.870968     -2.421374     7.991366   \n",
       "...                ...               ...           ...          ...   \n",
       "2734          0.152613          2.000000     -2.415835     6.432407   \n",
       "2735          0.335203          1.700000     -2.001320     6.164147   \n",
       "2736          0.264178          1.833333     -2.414068     5.737009   \n",
       "2737          0.338995          1.815789     -2.065301     7.218862   \n",
       "2738          0.282757          1.789474     -2.330174     9.102997   \n",
       "\n",
       "      PEOE_VSA12  PEOE_VSA6   SMR_VSA3  SlogP_VSA3  SlogP_VSA8  EState_VSA6  \\\n",
       "0       0.000000  12.132734   9.551078    0.000000   38.974594    43.638476   \n",
       "1       5.948339   0.000000   9.967957    0.000000   10.440599    11.336786   \n",
       "2       9.837253  29.297126   4.983979    9.837253   10.902925    24.265468   \n",
       "3       5.948339  35.334614  15.284746    0.000000   11.126903    12.263211   \n",
       "4       0.000000  23.362825  19.935914    6.420822    0.000000    18.460054   \n",
       "...          ...        ...        ...         ...         ...          ...   \n",
       "2734    0.000000  35.334614   9.967957   11.343745   11.257379     6.066367   \n",
       "2735    0.000000  30.331835   4.983979    0.000000   10.902925    36.528679   \n",
       "2736    5.948339  38.112943   9.551078   11.784535   11.126903    11.614772   \n",
       "2737    5.907180  59.014740  24.544948   18.386966   43.634305     6.196844   \n",
       "2738    0.000000  28.147817   9.799819    4.794537    0.000000     0.000000   \n",
       "\n",
       "      NumHAcceptors  NumSaturatedCarbocycles  fr_bicyclic  TARGET  Kfold  \n",
       "0                 6                        0            1     1.0      0  \n",
       "1                 6                        0            0     1.0      1  \n",
       "2                 4                        0            1     0.0      1  \n",
       "3                 5                        0            0     0.0      0  \n",
       "4                 9                        0            1     1.0      4  \n",
       "...             ...                      ...          ...     ...    ...  \n",
       "2734              6                        0            0     1.0      3  \n",
       "2735              2                        0            1     0.0      6  \n",
       "2736              7                        0            0     1.0      8  \n",
       "2737              9                        0            2     0.0      5  \n",
       "2738              3                        0            0     1.0      5  \n",
       "\n",
       "[2739 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'..\\10_fold_cross_validation\\train_10folds.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5676349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MaxPartialCharge', 'FpDensityMorgan2', 'BCUT2D_CHGLO', 'BCUT2D_MRHI',\n",
       "       'PEOE_VSA12', 'PEOE_VSA6', 'SMR_VSA3', 'SlogP_VSA3', 'SlogP_VSA8',\n",
       "       'EState_VSA6', 'NumHAcceptors', 'NumSaturatedCarbocycles',\n",
       "       'fr_bicyclic', 'TARGET', 'Kfold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b6fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold, data):\n",
    "    # load the full training data with folds\n",
    "    df = data\n",
    "    # all columns are features except target and kfold columns\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"TARGET\", \"Kfold\")\n",
    "    ]\n",
    "    # get training data using folds\n",
    "    df_train = df[df.Kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.Kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    X_train = df_train[features].values\n",
    "    # get validation data\n",
    "    X_valid = df_valid[features].values\n",
    "    # initialize Logistic Regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, df_train.TARGET)\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    auc = roc_auc_score(df_valid.TARGET.values, valid_preds)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_true = df_valid.TARGET.values\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    precision_1 = precision_score(y_true,y_pred,pos_label=1)\n",
    "    precision_0 = precision_score(y_true,y_pred,pos_label=0)\n",
    "    recall_1 = recall_score(y_true,y_pred,pos_label=1)\n",
    "    recall_0 = recall_score(y_true,y_pred,pos_label=0)\n",
    "    f1score = f1_score(y_true,y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    MCC = matthews_corrcoef(y_true,y_pred)\n",
    "    print(f\"Fold = {fold}, AUC = {auc}, Accuracy = {accuracy}, \\\n",
    "          Precision_1 = {precision_1}, Precision_0 = {precision_0}\\\n",
    "          Recall_1 = {recall_1}, Recall_0 = {recall_0}, F1Score = {f1score}, kappa = {kappa}, MCC = {MCC}\")\n",
    "    \n",
    "    return auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723cb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.8591065292096219, Accuracy = 0.7992700729927007,           Precision_1 = 0.723404255319149, Precision_0 = 0.8388888888888889          Recall_1 = 0.7010309278350515, Recall_0 = 0.8531073446327684, F1Score = 0.7120418848167538, kappa = 0.5580385946389818, MCC = 0.5582008165095612\n",
      "Fold = 1, AUC = 0.8764051488147242, Accuracy = 0.8065693430656934,           Precision_1 = 0.782051282051282, Precision_0 = 0.8163265306122449          Recall_1 = 0.6288659793814433, Recall_0 = 0.903954802259887, F1Score = 0.6971428571428572, kappa = 0.557498933512097, MCC = 0.5646486818015339\n",
      "Fold = 2, AUC = 0.8630671559205544, Accuracy = 0.7883211678832117,           Precision_1 = 0.7142857142857143, Precision_0 = 0.825136612021858          Recall_1 = 0.6701030927835051, Recall_0 = 0.8531073446327684, F1Score = 0.6914893617021276, kappa = 0.5306279165928289, MCC = 0.5312545447330203\n",
      "Fold = 3, AUC = 0.8747743025219873, Accuracy = 0.8211678832116789,           Precision_1 = 0.8, Precision_0 = 0.8298969072164949          Recall_1 = 0.6597938144329897, Recall_0 = 0.9096045197740112, F1Score = 0.7231638418079096, kappa = 0.592880101886106, MCC = 0.5988841705131419\n",
      "Fold = 4, AUC = 0.8800163084629273, Accuracy = 0.8248175182481752,           Precision_1 = 0.7951807228915663, Precision_0 = 0.837696335078534          Recall_1 = 0.6804123711340206, Recall_0 = 0.903954802259887, F1Score = 0.7333333333333334, kappa = 0.6040700824853995, MCC = 0.6081386169878046\n",
      "Fold = 5, AUC = 0.9068670277826314, Accuracy = 0.8394160583941606,           Precision_1 = 0.7912087912087912, Precision_0 = 0.8633879781420765          Recall_1 = 0.7422680412371134, Recall_0 = 0.8926553672316384, F1Score = 0.7659574468085107, kappa = 0.6439246263807668, MCC = 0.644685048662435\n",
      "Fold = 6, AUC = 0.8588153066573475, Accuracy = 0.7956204379562044,           Precision_1 = 0.7411764705882353, Precision_0 = 0.8201058201058201          Recall_1 = 0.6494845360824743, Recall_0 = 0.8757062146892656, F1Score = 0.6923076923076924, kappa = 0.5402960033555037, MCC = 0.5429367068494199\n",
      "Fold = 7, AUC = 0.8469043042693226, Accuracy = 0.7846715328467153,           Precision_1 = 0.6862745098039216, Precision_0 = 0.8430232558139535          Recall_1 = 0.7216494845360825, Recall_0 = 0.8192090395480226, F1Score = 0.7035175879396985, kappa = 0.5346306638263573, MCC = 0.5350469215994972\n",
      "Fold = 8, AUC = 0.9092345505617977, Accuracy = 0.8357664233576643,           Precision_1 = 0.7524752475247525, Precision_0 = 0.884393063583815          Recall_1 = 0.7916666666666666, Recall_0 = 0.8595505617977528, F1Score = 0.7715736040609136, kappa = 0.6434973688775806, MCC = 0.64400280780206\n",
      "Fold = 9, AUC = 0.8615819209039548, Accuracy = 0.7875457875457875,           Precision_1 = 0.6862745098039216, Precision_0 = 0.847953216374269          Recall_1 = 0.7291666666666666, Recall_0 = 0.8192090395480226, F1Score = 0.7070707070707071, kappa = 0.5406440382941688, MCC = 0.5412554910783196\n",
      "\n",
      "\n",
      "Mean Scores: AUC = 0.8736772555104869,       Accuracy = 0.8083166225501992,       Precision_1 = 0.7472331503477334, Precision_0 = 0.8406808607837954      Recall_1 = 0.6974441580756015, Recall_0 = 0.8690059036374025      F1Score = 0.7197598316990503       Kappa = 0.5746108329849791       MCC = 0.5769053806536795\n"
     ]
    }
   ],
   "source": [
    "aucs, accuracies, precisions_1, precisions_0, recalls_1, recalls_0, f1scores, kappas, MCCs = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for fold_ in range(10):\n",
    "    auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model = run(fold_, data)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions_1.append(precision_1)\n",
    "    precisions_0.append(precision_0)\n",
    "    recalls_1.append(recall_1)\n",
    "    recalls_0.append(recall_0)\n",
    "    f1scores.append(f1score)\n",
    "    kappas.append(kappa)\n",
    "    MCCs.append(MCC)\n",
    "    # filename = 'XGBoost_' + str(fold_) + '.pkl'\n",
    "    # joblib.dump(model, filename)\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Scores: AUC = {np.mean(np.array(aucs))}, \\\n",
    "      Accuracy = {np.mean(np.array(accuracies))}, \\\n",
    "      Precision_1 = {np.mean(np.array(precisions_1))}, Precision_0 = {np.mean(np.array(precisions_0))}\\\n",
    "      Recall_1 = {np.mean(np.array(recalls_1))}, Recall_0 = {np.mean(np.array(recalls_0))}\\\n",
    "      F1Score = {np.mean(np.array(f1scores))} \\\n",
    "      Kappa = {np.mean(np.array(kappas))} \\\n",
    "      MCC = {np.mean(np.array(MCCs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d66d9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.558039</td>\n",
       "      <td>0.558201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.564649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.863067</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.825137</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.531255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.874774</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.592880</td>\n",
       "      <td>0.598884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.880016</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.608139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.906867</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.863388</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.643925</td>\n",
       "      <td>0.644685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.858815</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.540296</td>\n",
       "      <td>0.542937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.784672</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.534631</td>\n",
       "      <td>0.535047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.835766</td>\n",
       "      <td>0.909235</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.884393</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.643497</td>\n",
       "      <td>0.644003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.787546</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.847953</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.540644</td>\n",
       "      <td>0.541255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0   F1score  \\\n",
       "0  0.799270  0.859107     0.723404     0.838889  0.701031  0.853107  0.712042   \n",
       "1  0.806569  0.876405     0.782051     0.816327  0.628866  0.903955  0.697143   \n",
       "2  0.788321  0.863067     0.714286     0.825137  0.670103  0.853107  0.691489   \n",
       "3  0.821168  0.874774     0.800000     0.829897  0.659794  0.909605  0.723164   \n",
       "4  0.824818  0.880016     0.795181     0.837696  0.680412  0.903955  0.733333   \n",
       "5  0.839416  0.906867     0.791209     0.863388  0.742268  0.892655  0.765957   \n",
       "6  0.795620  0.858815     0.741176     0.820106  0.649485  0.875706  0.692308   \n",
       "7  0.784672  0.846904     0.686275     0.843023  0.721649  0.819209  0.703518   \n",
       "8  0.835766  0.909235     0.752475     0.884393  0.791667  0.859551  0.771574   \n",
       "9  0.787546  0.861582     0.686275     0.847953  0.729167  0.819209  0.707071   \n",
       "\n",
       "      Kappa       MCC  \n",
       "0  0.558039  0.558201  \n",
       "1  0.557499  0.564649  \n",
       "2  0.530628  0.531255  \n",
       "3  0.592880  0.598884  \n",
       "4  0.604070  0.608139  \n",
       "5  0.643925  0.644685  \n",
       "6  0.540296  0.542937  \n",
       "7  0.534631  0.535047  \n",
       "8  0.643497  0.644003  \n",
       "9  0.540644  0.541255  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics = pd.DataFrame(columns=['Accuracy','AUC','Precision_1','Precision_0','Recall_1','Recall_0','F1score','Kappa','MCC'])\n",
    "fold_metrics['Accuracy'] = np.array(accuracies)\n",
    "fold_metrics['AUC'] = np.array(aucs)\n",
    "fold_metrics['Precision_1'] = np.array(precisions_1)\n",
    "fold_metrics['Precision_0'] = np.array(precisions_0)\n",
    "fold_metrics['Recall_1'] = np.array(recalls_1)\n",
    "fold_metrics['Recall_0'] = np.array(recalls_0)\n",
    "fold_metrics['F1score'] = np.array(f1scores)\n",
    "fold_metrics['Kappa'] = np.array(kappas)\n",
    "fold_metrics['MCC'] = np.array(MCCs)\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b997b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.558039</td>\n",
       "      <td>0.558201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.564649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.863067</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.825137</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.531255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.874774</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.592880</td>\n",
       "      <td>0.598884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.880016</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.608139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.906867</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.863388</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.643925</td>\n",
       "      <td>0.644685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.858815</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.540296</td>\n",
       "      <td>0.542937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.784672</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.534631</td>\n",
       "      <td>0.535047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.835766</td>\n",
       "      <td>0.909235</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.884393</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.643497</td>\n",
       "      <td>0.644003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.787546</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.847953</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.540644</td>\n",
       "      <td>0.541255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.808317</td>\n",
       "      <td>0.873677</td>\n",
       "      <td>0.747233</td>\n",
       "      <td>0.840681</td>\n",
       "      <td>0.697444</td>\n",
       "      <td>0.869006</td>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.574611</td>\n",
       "      <td>0.576905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0  \\\n",
       "0   0.799270  0.859107     0.723404     0.838889  0.701031  0.853107   \n",
       "1   0.806569  0.876405     0.782051     0.816327  0.628866  0.903955   \n",
       "2   0.788321  0.863067     0.714286     0.825137  0.670103  0.853107   \n",
       "3   0.821168  0.874774     0.800000     0.829897  0.659794  0.909605   \n",
       "4   0.824818  0.880016     0.795181     0.837696  0.680412  0.903955   \n",
       "5   0.839416  0.906867     0.791209     0.863388  0.742268  0.892655   \n",
       "6   0.795620  0.858815     0.741176     0.820106  0.649485  0.875706   \n",
       "7   0.784672  0.846904     0.686275     0.843023  0.721649  0.819209   \n",
       "8   0.835766  0.909235     0.752475     0.884393  0.791667  0.859551   \n",
       "9   0.787546  0.861582     0.686275     0.847953  0.729167  0.819209   \n",
       "10  0.808317  0.873677     0.747233     0.840681  0.697444  0.869006   \n",
       "\n",
       "     F1score     Kappa       MCC  \n",
       "0   0.712042  0.558039  0.558201  \n",
       "1   0.697143  0.557499  0.564649  \n",
       "2   0.691489  0.530628  0.531255  \n",
       "3   0.723164  0.592880  0.598884  \n",
       "4   0.733333  0.604070  0.608139  \n",
       "5   0.765957  0.643925  0.644685  \n",
       "6   0.692308  0.540296  0.542937  \n",
       "7   0.703518  0.534631  0.535047  \n",
       "8   0.771574  0.643497  0.644003  \n",
       "9   0.707071  0.540644  0.541255  \n",
       "10  0.719760  0.574611  0.576905  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics.loc[10,:] = [np.mean(np.array(accuracies)), np.mean(np.array(aucs)), np.mean(np.array(precisions_1)),\n",
    "                               np.mean(np.array(precisions_0)), np.mean(np.array(recalls_1)), np.mean(np.array(recalls_0)),\n",
    "                            np.mean(np.array(f1scores)), np.mean(np.array(kappas)), np.mean(np.array(MCCs))]\n",
    "\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a729d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.558039</td>\n",
       "      <td>0.558201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.564649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.863067</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.825137</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.531255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.874774</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.592880</td>\n",
       "      <td>0.598884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.880016</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.608139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.906867</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.863388</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.643925</td>\n",
       "      <td>0.644685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.858815</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.540296</td>\n",
       "      <td>0.542937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.784672</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.534631</td>\n",
       "      <td>0.535047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.835766</td>\n",
       "      <td>0.909235</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.884393</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.643497</td>\n",
       "      <td>0.644003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.787546</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.847953</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.540644</td>\n",
       "      <td>0.541255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.808317</td>\n",
       "      <td>0.873677</td>\n",
       "      <td>0.747233</td>\n",
       "      <td>0.840681</td>\n",
       "      <td>0.697444</td>\n",
       "      <td>0.869006</td>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.574611</td>\n",
       "      <td>0.576905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.019554</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.032015</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.041612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0  \\\n",
       "0   0.799270  0.859107     0.723404     0.838889  0.701031  0.853107   \n",
       "1   0.806569  0.876405     0.782051     0.816327  0.628866  0.903955   \n",
       "2   0.788321  0.863067     0.714286     0.825137  0.670103  0.853107   \n",
       "3   0.821168  0.874774     0.800000     0.829897  0.659794  0.909605   \n",
       "4   0.824818  0.880016     0.795181     0.837696  0.680412  0.903955   \n",
       "5   0.839416  0.906867     0.791209     0.863388  0.742268  0.892655   \n",
       "6   0.795620  0.858815     0.741176     0.820106  0.649485  0.875706   \n",
       "7   0.784672  0.846904     0.686275     0.843023  0.721649  0.819209   \n",
       "8   0.835766  0.909235     0.752475     0.884393  0.791667  0.859551   \n",
       "9   0.787546  0.861582     0.686275     0.847953  0.729167  0.819209   \n",
       "10  0.808317  0.873677     0.747233     0.840681  0.697444  0.869006   \n",
       "11  0.019480  0.019554     0.041688     0.019675  0.046851  0.032015   \n",
       "\n",
       "     F1score     Kappa       MCC  \n",
       "0   0.712042  0.558039  0.558201  \n",
       "1   0.697143  0.557499  0.564649  \n",
       "2   0.691489  0.530628  0.531255  \n",
       "3   0.723164  0.592880  0.598884  \n",
       "4   0.733333  0.604070  0.608139  \n",
       "5   0.765957  0.643925  0.644685  \n",
       "6   0.692308  0.540296  0.542937  \n",
       "7   0.703518  0.534631  0.535047  \n",
       "8   0.771574  0.643497  0.644003  \n",
       "9   0.707071  0.540644  0.541255  \n",
       "10  0.719760  0.574611  0.576905  \n",
       "11  0.027502  0.041452  0.041612  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics.loc[11,:] = [np.std(np.array(accuracies)), np.std(np.array(aucs)), np.std(np.array(precisions_1)),\n",
    "                               np.std(np.array(precisions_0)), np.std(np.array(recalls_1)), np.std(np.array(recalls_0)),\n",
    "                            np.std(np.array(f1scores)), np.std(np.array(kappas)), np.std(np.array(MCCs))]\n",
    "\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7850f367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold_0</th>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.558039</td>\n",
       "      <td>0.558201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_1</th>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.564649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_2</th>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.863067</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.825137</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.531255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_3</th>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.874774</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.592880</td>\n",
       "      <td>0.598884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_4</th>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.880016</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.608139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_5</th>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.906867</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.863388</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.643925</td>\n",
       "      <td>0.644685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_6</th>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.858815</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.540296</td>\n",
       "      <td>0.542937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_7</th>\n",
       "      <td>0.784672</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.534631</td>\n",
       "      <td>0.535047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_8</th>\n",
       "      <td>0.835766</td>\n",
       "      <td>0.909235</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.884393</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.643497</td>\n",
       "      <td>0.644003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_9</th>\n",
       "      <td>0.787546</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.847953</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.540644</td>\n",
       "      <td>0.541255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.808317</td>\n",
       "      <td>0.873677</td>\n",
       "      <td>0.747233</td>\n",
       "      <td>0.840681</td>\n",
       "      <td>0.697444</td>\n",
       "      <td>0.869006</td>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.574611</td>\n",
       "      <td>0.576905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.019554</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.032015</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.041612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0  \\\n",
       "Fold_0  0.799270  0.859107     0.723404     0.838889  0.701031  0.853107   \n",
       "Fold_1  0.806569  0.876405     0.782051     0.816327  0.628866  0.903955   \n",
       "Fold_2  0.788321  0.863067     0.714286     0.825137  0.670103  0.853107   \n",
       "Fold_3  0.821168  0.874774     0.800000     0.829897  0.659794  0.909605   \n",
       "Fold_4  0.824818  0.880016     0.795181     0.837696  0.680412  0.903955   \n",
       "Fold_5  0.839416  0.906867     0.791209     0.863388  0.742268  0.892655   \n",
       "Fold_6  0.795620  0.858815     0.741176     0.820106  0.649485  0.875706   \n",
       "Fold_7  0.784672  0.846904     0.686275     0.843023  0.721649  0.819209   \n",
       "Fold_8  0.835766  0.909235     0.752475     0.884393  0.791667  0.859551   \n",
       "Fold_9  0.787546  0.861582     0.686275     0.847953  0.729167  0.819209   \n",
       "Mean    0.808317  0.873677     0.747233     0.840681  0.697444  0.869006   \n",
       "Std     0.019480  0.019554     0.041688     0.019675  0.046851  0.032015   \n",
       "\n",
       "         F1score     Kappa       MCC  \n",
       "Fold_0  0.712042  0.558039  0.558201  \n",
       "Fold_1  0.697143  0.557499  0.564649  \n",
       "Fold_2  0.691489  0.530628  0.531255  \n",
       "Fold_3  0.723164  0.592880  0.598884  \n",
       "Fold_4  0.733333  0.604070  0.608139  \n",
       "Fold_5  0.765957  0.643925  0.644685  \n",
       "Fold_6  0.692308  0.540296  0.542937  \n",
       "Fold_7  0.703518  0.534631  0.535047  \n",
       "Fold_8  0.771574  0.643497  0.644003  \n",
       "Fold_9  0.707071  0.540644  0.541255  \n",
       "Mean    0.719760  0.574611  0.576905  \n",
       "Std     0.027502  0.041452  0.041612  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics.index = ['Fold_0','Fold_1','Fold_2','Fold_3','Fold_4','Fold_5','Fold_6','Fold_7','Fold_8','Fold_9','Mean','Std']\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3c1b0",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5428955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a81100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOPT:\n",
    "    def __init__(self, data, space):\n",
    "        self.space = space\n",
    "        self.data = data\n",
    "        self.trials = Trials()\n",
    "    \n",
    "    def _split_data(self, fold):\n",
    "        df = self.data\n",
    "        # all columns are features except target and kfold columns\n",
    "        features = [\n",
    "            f for f in df.columns if f not in (\"TARGET\", \"Kfold\")\n",
    "        ]\n",
    "        # get training data using folds\n",
    "        df_train = df[df.Kfold != fold].reset_index(drop=True)\n",
    "        # get validation data using folds\n",
    "        df_valid = df[df.Kfold == fold].reset_index(drop=True)\n",
    "        # get training data\n",
    "        X_train = df_train[features].values\n",
    "        # get validation data\n",
    "        X_test = df_valid[features].values\n",
    "        y_train = df_train.TARGET.values\n",
    "        y_test = df_valid.TARGET.values\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    def _objective(self,space):\n",
    "        clf= LogisticRegression(**space)\n",
    "        \n",
    "        \n",
    "        accuracies = []\n",
    "        for fold_ in range(10):\n",
    "            X_train, y_train, X_test, y_test = self._split_data(fold_)\n",
    "            evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "        \n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "            pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, pred>0.5)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        final_accuracy = np.mean(np.array(accuracies))\n",
    "        #print (\"SCORE:\", final_accuracy)\n",
    "        return {'loss': -final_accuracy, 'status': STATUS_OK }\n",
    "    \n",
    "    def search_hyperparameters(self):\n",
    "\n",
    "        best_hyperparams = fmin(fn = self._objective,\n",
    "                                space = self.space,\n",
    "                                algo = tpe.suggest,\n",
    "                                max_evals = 500,\n",
    "                                trials = self.trials)\n",
    "        return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31bc92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'C': hp.loguniform('C', np.log(0.01), np.log(10)),\n",
    "    'penalty': hp.choice('penalty', ['l2'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0feebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [22:35<00:00,  2.71s/trial, best loss: -0.8148899762038448]\n",
      "{'C': 3.6918690818779667, 'penalty': 0}\n"
     ]
    }
   ],
   "source": [
    "bayes_opt = BayesianOPT(data, space)\n",
    "best_params = bayes_opt.search_hyperparameters()\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7ecf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9611638174070645, 'gamma': 0.5344801495975495, 'learning_rate': 0.048882041230470526, 'max_depth': 14.0, 'min_child_weight': 0.0, 'reg_alpha': 0.0, 'reg_lambda': 1.164764580743543}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1908646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c3066ce",
   "metadata": {},
   "source": [
    "# Train the model with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3312ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold, data, best_hyper_parameters):\n",
    "    # load the full training data with folds\n",
    "    df = data\n",
    "    # all columns are features except target and kfold columns\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"TARGET\", \"Kfold\")\n",
    "    ]\n",
    "    # get training data using folds\n",
    "    df_train = df[df.Kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.Kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    X_train = df_train[features].values\n",
    "    # get validation data\n",
    "    X_valid = df_valid[features].values\n",
    "    # initialize Logistic Regression model\n",
    "    model = XGBClassifier(n_jobs = -1,\n",
    "                          colsample_bytree= best_hyper_parameters[\"colsample_bytree\"], \n",
    "                          gamma= best_hyper_parameters[\"gamma\"], \n",
    "                          max_depth= int(best_hyper_parameters[\"max_depth\"]), \n",
    "                          min_child_weight= best_hyper_parameters[\"min_child_weight\"], \n",
    "                          reg_alpha= best_hyper_parameters[\"reg_alpha\"], \n",
    "                          reg_lambda= best_hyper_parameters[\"reg_lambda\"])\n",
    "    \n",
    "    model.fit(X_train, df_train.TARGET.values)\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    auc = roc_auc_score(df_valid.TARGET.values, valid_preds)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_true = df_valid.TARGET.values\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    precision_1 = precision_score(y_true,y_pred,pos_label=1)\n",
    "    precision_0 = precision_score(y_true,y_pred,pos_label=0)\n",
    "    recall_1 = recall_score(y_true,y_pred,pos_label=1)\n",
    "    recall_0 = recall_score(y_true,y_pred,pos_label=0)\n",
    "    f1score = f1_score(y_true,y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    MCC = matthews_corrcoef(y_true,y_pred)\n",
    "    print(f\"Fold = {fold}, AUC = {auc}, Accuracy = {accuracy}, \\\n",
    "          Precision_1 = {precision_1}, Precision_0 = {precision_0}\\\n",
    "          Recall_1 = {recall_1}, Recall_0 = {recall_0}, F1Score = {f1score}, kappa = {kappa}, MCC = {MCC}\")\n",
    "    \n",
    "    return auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2a6feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.9680820082707206, Accuracy = 0.9598540145985401,           Precision_1 = 0.9479166666666666, Precision_0 = 0.9662921348314607          Recall_1 = 0.9381443298969072, Recall_0 = 0.9717514124293786, F1Score = 0.9430051813471502, kappa = 0.9120205499445385, MCC = 0.9120497223728334\n",
      "Fold = 1, AUC = 0.9729163026384763, Accuracy = 0.9343065693430657,           Precision_1 = 0.9438202247191011, Precision_0 = 0.9297297297297298          Recall_1 = 0.865979381443299, Recall_0 = 0.9717514124293786, F1Score = 0.9032258064516129, kappa = 0.8536411656478129, MCC = 0.8554529191182063\n",
      "Fold = 2, AUC = 0.9726250800862019, Accuracy = 0.9233576642335767,           Precision_1 = 0.8958333333333334, Precision_0 = 0.9382022471910112          Recall_1 = 0.8865979381443299, Recall_0 = 0.943502824858757, F1Score = 0.8911917098445595, kappa = 0.8320392317123008, MCC = 0.8320658458108835\n",
      "Fold = 3, AUC = 0.9630147358611452, Accuracy = 0.927007299270073,           Precision_1 = 0.8888888888888888, Precision_0 = 0.9485714285714286          Recall_1 = 0.9072164948453608, Recall_0 = 0.9378531073446328, F1Score = 0.8979591836734694, kappa = 0.84115021160647, MCC = 0.8412563564848091\n",
      "Fold = 4, AUC = 0.9681984972916303, Accuracy = 0.9343065693430657,           Precision_1 = 0.898989898989899, Precision_0 = 0.9542857142857143          Recall_1 = 0.9175257731958762, Recall_0 = 0.943502824858757, F1Score = 0.9081632653061225, kappa = 0.857035190445823, MCC = 0.8571433398521561\n",
      "Fold = 5, AUC = 0.9844487157085444, Accuracy = 0.9635036496350365,           Precision_1 = 0.9484536082474226, Precision_0 = 0.9717514124293786          Recall_1 = 0.9484536082474226, Recall_0 = 0.9717514124293786, F1Score = 0.9484536082474226, kappa = 0.9202050206768012, MCC = 0.9202050206768012\n",
      "Fold = 6, AUC = 0.9782747976003262, Accuracy = 0.9452554744525548,           Precision_1 = 0.91, Precision_0 = 0.9655172413793104          Recall_1 = 0.9381443298969072, Recall_0 = 0.9491525423728814, F1Score = 0.9238578680203046, kappa = 0.8811382960263752, MCC = 0.8813873778845119\n",
      "Fold = 7, AUC = 0.9772263964121382, Accuracy = 0.9306569343065694,           Precision_1 = 0.9431818181818182, Precision_0 = 0.9247311827956989          Recall_1 = 0.8556701030927835, Recall_0 = 0.9717514124293786, F1Score = 0.8972972972972973, kappa = 0.8451424831935272, MCC = 0.8474254484084159\n",
      "Fold = 8, AUC = 0.9806296816479401, Accuracy = 0.9343065693430657,           Precision_1 = 0.8979591836734694, Precision_0 = 0.9545454545454546          Recall_1 = 0.9166666666666666, Recall_0 = 0.9438202247191011, F1Score = 0.9072164948453607, kappa = 0.856377402446127, MCC = 0.85648646576169\n",
      "Fold = 9, AUC = 0.9817561205273069, Accuracy = 0.9633699633699634,           Precision_1 = 0.967391304347826, Precision_0 = 0.9613259668508287          Recall_1 = 0.9270833333333334, Recall_0 = 0.9830508474576272, F1Score = 0.9468085106382979, kappa = 0.9188948306595366, MCC = 0.9193787754830997\n",
      "\n",
      "\n",
      "Mean Scores: AUC = 0.9747172336044428,       Accuracy = 0.9415924707895511,       Precision_1 = 0.9242434927048425, Precision_0 = 0.9514952512610015      Recall_1 = 0.9101481958762886, Recall_0 = 0.958788802132927      F1Score = 0.9167178925671597       Kappa = 0.8717644382359312       MCC = 0.8722851271853406\n"
     ]
    }
   ],
   "source": [
    "aucs, accuracies, precisions_1, precisions_0, recalls_1, recalls_0, f1scores, kappas, MCCs = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for fold_ in range(10):\n",
    "    auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model = run(fold_, data, best_params)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions_1.append(precision_1)\n",
    "    precisions_0.append(precision_0)\n",
    "    recalls_1.append(recall_1)\n",
    "    recalls_0.append(recall_0)\n",
    "    f1scores.append(f1score)\n",
    "    kappas.append(kappa)\n",
    "    MCCs.append(MCC)\n",
    "    filename = 'XGBoost_' + str(fold_) + '.pkl'\n",
    "    joblib.dump(model, filename)\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Scores: AUC = {np.mean(np.array(aucs))}, \\\n",
    "      Accuracy = {np.mean(np.array(accuracies))}, \\\n",
    "      Precision_1 = {np.mean(np.array(precisions_1))}, Precision_0 = {np.mean(np.array(precisions_0))}\\\n",
    "      Recall_1 = {np.mean(np.array(recalls_1))}, Recall_0 = {np.mean(np.array(recalls_0))}\\\n",
    "      F1Score = {np.mean(np.array(f1scores))} \\\n",
    "      Kappa = {np.mean(np.array(kappas))} \\\n",
    "      MCC = {np.mean(np.array(MCCs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1279875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
