{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40156c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, \\\n",
    "  ConfusionMatrixDisplay, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce82414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxPartialCharge</th>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <th>BCUT2D_CHGLO</th>\n",
       "      <th>BCUT2D_MRHI</th>\n",
       "      <th>PEOE_VSA12</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>SMR_VSA3</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>SlogP_VSA8</th>\n",
       "      <th>EState_VSA6</th>\n",
       "      <th>NumHAcceptors</th>\n",
       "      <th>NumSaturatedCarbocycles</th>\n",
       "      <th>fr_bicyclic</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.335201</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>-2.072068</td>\n",
       "      <td>5.975550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>9.551078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.974594</td>\n",
       "      <td>43.638476</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.226791</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.362642</td>\n",
       "      <td>7.150190</td>\n",
       "      <td>5.948339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.967957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.440599</td>\n",
       "      <td>11.336786</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.211302</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>-2.089721</td>\n",
       "      <td>7.912349</td>\n",
       "      <td>9.837253</td>\n",
       "      <td>29.297126</td>\n",
       "      <td>4.983979</td>\n",
       "      <td>9.837253</td>\n",
       "      <td>10.902925</td>\n",
       "      <td>24.265468</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226898</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>-2.357502</td>\n",
       "      <td>6.433493</td>\n",
       "      <td>5.948339</td>\n",
       "      <td>35.334614</td>\n",
       "      <td>15.284746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.126903</td>\n",
       "      <td>12.263211</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158370</td>\n",
       "      <td>1.870968</td>\n",
       "      <td>-2.421374</td>\n",
       "      <td>7.991366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.362825</td>\n",
       "      <td>19.935914</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.460054</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>0.152613</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.415835</td>\n",
       "      <td>6.432407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.334614</td>\n",
       "      <td>9.967957</td>\n",
       "      <td>11.343745</td>\n",
       "      <td>11.257379</td>\n",
       "      <td>6.066367</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>0.335203</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>-2.001320</td>\n",
       "      <td>6.164147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.331835</td>\n",
       "      <td>4.983979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.902925</td>\n",
       "      <td>36.528679</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>0.264178</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>-2.414068</td>\n",
       "      <td>5.737009</td>\n",
       "      <td>5.948339</td>\n",
       "      <td>38.112943</td>\n",
       "      <td>9.551078</td>\n",
       "      <td>11.784535</td>\n",
       "      <td>11.126903</td>\n",
       "      <td>11.614772</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>0.338995</td>\n",
       "      <td>1.815789</td>\n",
       "      <td>-2.065301</td>\n",
       "      <td>7.218862</td>\n",
       "      <td>5.907180</td>\n",
       "      <td>59.014740</td>\n",
       "      <td>24.544948</td>\n",
       "      <td>18.386966</td>\n",
       "      <td>43.634305</td>\n",
       "      <td>6.196844</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>0.282757</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>-2.330174</td>\n",
       "      <td>9.102997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.147817</td>\n",
       "      <td>9.799819</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2739 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MaxPartialCharge  FpDensityMorgan2  BCUT2D_CHGLO  BCUT2D_MRHI  \\\n",
       "0             0.335201          1.714286     -2.072068     5.975550   \n",
       "1             0.226791          2.000000     -2.362642     7.150190   \n",
       "2             0.211302          1.772727     -2.089721     7.912349   \n",
       "3             0.226898          1.869565     -2.357502     6.433493   \n",
       "4             0.158370          1.870968     -2.421374     7.991366   \n",
       "...                ...               ...           ...          ...   \n",
       "2734          0.152613          2.000000     -2.415835     6.432407   \n",
       "2735          0.335203          1.700000     -2.001320     6.164147   \n",
       "2736          0.264178          1.833333     -2.414068     5.737009   \n",
       "2737          0.338995          1.815789     -2.065301     7.218862   \n",
       "2738          0.282757          1.789474     -2.330174     9.102997   \n",
       "\n",
       "      PEOE_VSA12  PEOE_VSA6   SMR_VSA3  SlogP_VSA3  SlogP_VSA8  EState_VSA6  \\\n",
       "0       0.000000  12.132734   9.551078    0.000000   38.974594    43.638476   \n",
       "1       5.948339   0.000000   9.967957    0.000000   10.440599    11.336786   \n",
       "2       9.837253  29.297126   4.983979    9.837253   10.902925    24.265468   \n",
       "3       5.948339  35.334614  15.284746    0.000000   11.126903    12.263211   \n",
       "4       0.000000  23.362825  19.935914    6.420822    0.000000    18.460054   \n",
       "...          ...        ...        ...         ...         ...          ...   \n",
       "2734    0.000000  35.334614   9.967957   11.343745   11.257379     6.066367   \n",
       "2735    0.000000  30.331835   4.983979    0.000000   10.902925    36.528679   \n",
       "2736    5.948339  38.112943   9.551078   11.784535   11.126903    11.614772   \n",
       "2737    5.907180  59.014740  24.544948   18.386966   43.634305     6.196844   \n",
       "2738    0.000000  28.147817   9.799819    4.794537    0.000000     0.000000   \n",
       "\n",
       "      NumHAcceptors  NumSaturatedCarbocycles  fr_bicyclic  TARGET  Kfold  \n",
       "0                 6                        0            1     1.0      0  \n",
       "1                 6                        0            0     1.0      1  \n",
       "2                 4                        0            1     0.0      1  \n",
       "3                 5                        0            0     0.0      0  \n",
       "4                 9                        0            1     1.0      4  \n",
       "...             ...                      ...          ...     ...    ...  \n",
       "2734              6                        0            0     1.0      3  \n",
       "2735              2                        0            1     0.0      6  \n",
       "2736              7                        0            0     1.0      8  \n",
       "2737              9                        0            2     0.0      5  \n",
       "2738              3                        0            0     1.0      5  \n",
       "\n",
       "[2739 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'..\\10_fold_cross_validation\\train_10folds.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b6fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold, data):\n",
    "    # load the full training data with folds\n",
    "    df = data\n",
    "    # all columns are features except target and kfold columns\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"TARGET\", \"Kfold\")\n",
    "    ]\n",
    "    # get training data using folds\n",
    "    df_train = df[df.Kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.Kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    X_train = df_train[features].values\n",
    "    # get validation data\n",
    "    X_valid = df_valid[features].values\n",
    "    # initialize Logistic Regression model\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, df_train.TARGET.values)\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    auc = roc_auc_score(df_valid.TARGET.values, valid_preds)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_true = df_valid.TARGET.values\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    precision_1 = precision_score(y_true,y_pred,pos_label=1)\n",
    "    precision_0 = precision_score(y_true,y_pred,pos_label=0)\n",
    "    recall_1 = recall_score(y_true,y_pred,pos_label=1)\n",
    "    recall_0 = recall_score(y_true,y_pred,pos_label=0)\n",
    "    f1score = f1_score(y_true,y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    MCC = matthews_corrcoef(y_true,y_pred)\n",
    "    print(f\"Fold = {fold}, AUC = {auc}, Accuracy = {accuracy}, \\\n",
    "          Precision_1 = {precision_1}, Precision_0 = {precision_0}\\\n",
    "          Recall_1 = {recall_1}, Recall_0 = {recall_0}, F1Score = {f1score}, kappa = {kappa}, MCC = {MCC}\")\n",
    "    \n",
    "    return auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723cb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.9354068379055274, Accuracy = 0.9343065693430657,           Precision_1 = 0.9157894736842105, Precision_0 = 0.9441340782122905          Recall_1 = 0.8969072164948454, Recall_0 = 0.9548022598870056, F1Score = 0.9062499999999999, kappa = 0.8556966469658844, MCC = 0.85580665930699\n",
      "Fold = 1, AUC = 0.9126041120624382, Accuracy = 0.9233576642335767,           Precision_1 = 0.9222222222222223, Precision_0 = 0.9239130434782609          Recall_1 = 0.8556701030927835, Recall_0 = 0.96045197740113, F1Score = 0.8877005347593583, kappa = 0.8296524364971283, MCC = 0.8309931849436243\n",
      "Fold = 2, AUC = 0.913128312656532, Accuracy = 0.9087591240875912,           Precision_1 = 0.8913043478260869, Precision_0 = 0.9175824175824175          Recall_1 = 0.845360824742268, Recall_0 = 0.943502824858757, F1Score = 0.8677248677248677, kappa = 0.7981613530555719, MCC = 0.7988124722825258\n",
      "Fold = 3, AUC = 0.9202341429320287, Accuracy = 0.916058394160584,           Precision_1 = 0.8557692307692307, Precision_0 = 0.9529411764705882          Recall_1 = 0.9175257731958762, Recall_0 = 0.9152542372881356, F1Score = 0.8855721393034824, kappa = 0.8194165854776778, MCC = 0.820656969396901\n",
      "Fold = 4, AUC = 0.9252431708311492, Accuracy = 0.927007299270073,           Precision_1 = 0.8737864077669902, Precision_0 = 0.9590643274853801          Recall_1 = 0.9278350515463918, Recall_0 = 0.9265536723163842, F1Score = 0.9, kappa = 0.8426101441782986, MCC = 0.8435509924482617\n",
      "Fold = 5, AUC = 0.9268740171238861, Accuracy = 0.927007299270073,           Precision_1 = 0.8888888888888888, Precision_0 = 0.9485714285714286          Recall_1 = 0.9072164948453608, Recall_0 = 0.9378531073446328, F1Score = 0.8979591836734694, kappa = 0.84115021160647, MCC = 0.8412563564848091\n",
      "Fold = 6, AUC = 0.9320286562991438, Accuracy = 0.927007299270073,           Precision_1 = 0.9052631578947369, Precision_0 = 0.9385474860335196          Recall_1 = 0.8865979381443299, Recall_0 = 0.9491525423728814, F1Score = 0.8958333333333333, kappa = 0.839662941073205, MCC = 0.839770892046502\n",
      "Fold = 7, AUC = 0.8967033607082532, Accuracy = 0.8978102189781022,           Precision_1 = 0.8631578947368421, Precision_0 = 0.9162011173184358          Recall_1 = 0.845360824742268, Recall_0 = 0.9265536723163842, F1Score = 0.8541666666666666, kappa = 0.775528117502487, MCC = 0.7756278230045502\n",
      "Fold = 8, AUC = 0.9247717696629214, Accuracy = 0.927007299270073,           Precision_1 = 0.8877551020408163, Precision_0 = 0.9488636363636364          Recall_1 = 0.90625, Recall_0 = 0.9382022471910112, F1Score = 0.8969072164948454, kappa = 0.8404193360512522, MCC = 0.8405263670389816\n",
      "Fold = 9, AUC = 0.9590689736346515, Accuracy = 0.9597069597069597,           Precision_1 = 0.9473684210526315, Precision_0 = 0.9662921348314607          Recall_1 = 0.9375, Recall_0 = 0.9717514124293786, F1Score = 0.9424083769633508, kappa = 0.9114237678081586, MCC = 0.9114533180139408\n",
      "\n",
      "\n",
      "Mean Scores: AUC = 0.9246063353816533,       Accuracy = 0.9248028127590171,       Precision_1 = 0.8951305146882657, Precision_0 = 0.9416110846347419      Recall_1 = 0.8926224226804124, Recall_0 = 0.9424077953405702      F1Score = 0.8934522318919376       Kappa = 0.8353721540216134       MCC = 0.8358455034967086\n"
     ]
    }
   ],
   "source": [
    "aucs, accuracies, precisions_1, precisions_0, recalls_1, recalls_0, f1scores, kappas, MCCs = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for fold_ in range(10):\n",
    "    auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model = run(fold_, data)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions_1.append(precision_1)\n",
    "    precisions_0.append(precision_0)\n",
    "    recalls_1.append(recall_1)\n",
    "    recalls_0.append(recall_0)\n",
    "    f1scores.append(f1score)\n",
    "    kappas.append(kappa)\n",
    "    MCCs.append(MCC)\n",
    "    #filename = 'SVM_' + str(fold_) + '.pkl'\n",
    "    #joblib.dump(model, filename)\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Scores: AUC = {np.mean(np.array(aucs))}, \\\n",
    "      Accuracy = {np.mean(np.array(accuracies))}, \\\n",
    "      Precision_1 = {np.mean(np.array(precisions_1))}, Precision_0 = {np.mean(np.array(precisions_0))}\\\n",
    "      Recall_1 = {np.mean(np.array(recalls_1))}, Recall_0 = {np.mean(np.array(recalls_0))}\\\n",
    "      F1Score = {np.mean(np.array(f1scores))} \\\n",
    "      Kappa = {np.mean(np.array(kappas))} \\\n",
    "      MCC = {np.mean(np.array(MCCs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d66d9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.855697</td>\n",
       "      <td>0.855807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923358</td>\n",
       "      <td>0.912604</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>0.829652</td>\n",
       "      <td>0.830993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908759</td>\n",
       "      <td>0.913128</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.867725</td>\n",
       "      <td>0.798161</td>\n",
       "      <td>0.798812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916058</td>\n",
       "      <td>0.920234</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>0.820657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.925243</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.843551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.926874</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.841150</td>\n",
       "      <td>0.841256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.932029</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.938547</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.839663</td>\n",
       "      <td>0.839771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.916201</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.775528</td>\n",
       "      <td>0.775628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.924772</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.938202</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.840419</td>\n",
       "      <td>0.840526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.959069</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.911424</td>\n",
       "      <td>0.911453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0   F1score  \\\n",
       "0  0.934307  0.935407     0.915789     0.944134  0.896907  0.954802  0.906250   \n",
       "1  0.923358  0.912604     0.922222     0.923913  0.855670  0.960452  0.887701   \n",
       "2  0.908759  0.913128     0.891304     0.917582  0.845361  0.943503  0.867725   \n",
       "3  0.916058  0.920234     0.855769     0.952941  0.917526  0.915254  0.885572   \n",
       "4  0.927007  0.925243     0.873786     0.959064  0.927835  0.926554  0.900000   \n",
       "5  0.927007  0.926874     0.888889     0.948571  0.907216  0.937853  0.897959   \n",
       "6  0.927007  0.932029     0.905263     0.938547  0.886598  0.949153  0.895833   \n",
       "7  0.897810  0.896703     0.863158     0.916201  0.845361  0.926554  0.854167   \n",
       "8  0.927007  0.924772     0.887755     0.948864  0.906250  0.938202  0.896907   \n",
       "9  0.959707  0.959069     0.947368     0.966292  0.937500  0.971751  0.942408   \n",
       "\n",
       "      Kappa       MCC  \n",
       "0  0.855697  0.855807  \n",
       "1  0.829652  0.830993  \n",
       "2  0.798161  0.798812  \n",
       "3  0.819417  0.820657  \n",
       "4  0.842610  0.843551  \n",
       "5  0.841150  0.841256  \n",
       "6  0.839663  0.839771  \n",
       "7  0.775528  0.775628  \n",
       "8  0.840419  0.840526  \n",
       "9  0.911424  0.911453  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics = pd.DataFrame(columns=['Accuracy','AUC','Precision_1','Precision_0','Recall_1','Recall_0','F1score','Kappa','MCC'])\n",
    "fold_metrics['Accuracy'] = np.array(accuracies)\n",
    "fold_metrics['AUC'] = np.array(aucs)\n",
    "fold_metrics['Precision_1'] = np.array(precisions_1)\n",
    "fold_metrics['Precision_0'] = np.array(precisions_0)\n",
    "fold_metrics['Recall_1'] = np.array(recalls_1)\n",
    "fold_metrics['Recall_0'] = np.array(recalls_0)\n",
    "fold_metrics['F1score'] = np.array(f1scores)\n",
    "fold_metrics['Kappa'] = np.array(kappas)\n",
    "fold_metrics['MCC'] = np.array(MCCs)\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b997b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.855697</td>\n",
       "      <td>0.855807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923358</td>\n",
       "      <td>0.912604</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>0.829652</td>\n",
       "      <td>0.830993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908759</td>\n",
       "      <td>0.913128</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.867725</td>\n",
       "      <td>0.798161</td>\n",
       "      <td>0.798812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916058</td>\n",
       "      <td>0.920234</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>0.820657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.925243</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.843551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.926874</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.841150</td>\n",
       "      <td>0.841256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.932029</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.938547</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.839663</td>\n",
       "      <td>0.839771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.916201</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.775528</td>\n",
       "      <td>0.775628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.924772</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.938202</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.840419</td>\n",
       "      <td>0.840526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.959069</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.911424</td>\n",
       "      <td>0.911453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.924803</td>\n",
       "      <td>0.924606</td>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.941611</td>\n",
       "      <td>0.892622</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.835372</td>\n",
       "      <td>0.835846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0  \\\n",
       "0   0.934307  0.935407     0.915789     0.944134  0.896907  0.954802   \n",
       "1   0.923358  0.912604     0.922222     0.923913  0.855670  0.960452   \n",
       "2   0.908759  0.913128     0.891304     0.917582  0.845361  0.943503   \n",
       "3   0.916058  0.920234     0.855769     0.952941  0.917526  0.915254   \n",
       "4   0.927007  0.925243     0.873786     0.959064  0.927835  0.926554   \n",
       "5   0.927007  0.926874     0.888889     0.948571  0.907216  0.937853   \n",
       "6   0.927007  0.932029     0.905263     0.938547  0.886598  0.949153   \n",
       "7   0.897810  0.896703     0.863158     0.916201  0.845361  0.926554   \n",
       "8   0.927007  0.924772     0.887755     0.948864  0.906250  0.938202   \n",
       "9   0.959707  0.959069     0.947368     0.966292  0.937500  0.971751   \n",
       "10  0.924803  0.924606     0.895131     0.941611  0.892622  0.942408   \n",
       "\n",
       "     F1score     Kappa       MCC  \n",
       "0   0.906250  0.855697  0.855807  \n",
       "1   0.887701  0.829652  0.830993  \n",
       "2   0.867725  0.798161  0.798812  \n",
       "3   0.885572  0.819417  0.820657  \n",
       "4   0.900000  0.842610  0.843551  \n",
       "5   0.897959  0.841150  0.841256  \n",
       "6   0.895833  0.839663  0.839771  \n",
       "7   0.854167  0.775528  0.775628  \n",
       "8   0.896907  0.840419  0.840526  \n",
       "9   0.942408  0.911424  0.911453  \n",
       "10  0.893452  0.835372  0.835846  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics.loc[10,:] = [np.mean(np.array(accuracies)), np.mean(np.array(aucs)), np.mean(np.array(precisions_1)),\n",
    "                               np.mean(np.array(precisions_0)), np.mean(np.array(recalls_1)), np.mean(np.array(recalls_0)),\n",
    "                            np.mean(np.array(f1scores)), np.mean(np.array(kappas)), np.mean(np.array(MCCs))]\n",
    "\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a729d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.855697</td>\n",
       "      <td>0.855807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923358</td>\n",
       "      <td>0.912604</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>0.829652</td>\n",
       "      <td>0.830993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908759</td>\n",
       "      <td>0.913128</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.867725</td>\n",
       "      <td>0.798161</td>\n",
       "      <td>0.798812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916058</td>\n",
       "      <td>0.920234</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>0.820657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.925243</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.843551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.926874</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.841150</td>\n",
       "      <td>0.841256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.932029</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.938547</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.839663</td>\n",
       "      <td>0.839771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.916201</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.775528</td>\n",
       "      <td>0.775628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.924772</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.938202</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.840419</td>\n",
       "      <td>0.840526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.959069</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.911424</td>\n",
       "      <td>0.911453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.924803</td>\n",
       "      <td>0.924606</td>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.941611</td>\n",
       "      <td>0.892622</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.835372</td>\n",
       "      <td>0.835846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>0.034029</td>\n",
       "      <td>0.033901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0  \\\n",
       "0   0.934307  0.935407     0.915789     0.944134  0.896907  0.954802   \n",
       "1   0.923358  0.912604     0.922222     0.923913  0.855670  0.960452   \n",
       "2   0.908759  0.913128     0.891304     0.917582  0.845361  0.943503   \n",
       "3   0.916058  0.920234     0.855769     0.952941  0.917526  0.915254   \n",
       "4   0.927007  0.925243     0.873786     0.959064  0.927835  0.926554   \n",
       "5   0.927007  0.926874     0.888889     0.948571  0.907216  0.937853   \n",
       "6   0.927007  0.932029     0.905263     0.938547  0.886598  0.949153   \n",
       "7   0.897810  0.896703     0.863158     0.916201  0.845361  0.926554   \n",
       "8   0.927007  0.924772     0.887755     0.948864  0.906250  0.938202   \n",
       "9   0.959707  0.959069     0.947368     0.966292  0.937500  0.971751   \n",
       "10  0.924803  0.924606     0.895131     0.941611  0.892622  0.942408   \n",
       "11  0.015468  0.015616     0.026697     0.016417  0.031875  0.016326   \n",
       "\n",
       "     F1score     Kappa       MCC  \n",
       "0   0.906250  0.855697  0.855807  \n",
       "1   0.887701  0.829652  0.830993  \n",
       "2   0.867725  0.798161  0.798812  \n",
       "3   0.885572  0.819417  0.820657  \n",
       "4   0.900000  0.842610  0.843551  \n",
       "5   0.897959  0.841150  0.841256  \n",
       "6   0.895833  0.839663  0.839771  \n",
       "7   0.854167  0.775528  0.775628  \n",
       "8   0.896907  0.840419  0.840526  \n",
       "9   0.942408  0.911424  0.911453  \n",
       "10  0.893452  0.835372  0.835846  \n",
       "11  0.022230  0.034029  0.033901  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics.loc[11,:] = [np.std(np.array(accuracies)), np.std(np.array(aucs)), np.std(np.array(precisions_1)),\n",
    "                               np.std(np.array(precisions_0)), np.std(np.array(recalls_1)), np.std(np.array(recalls_0)),\n",
    "                            np.std(np.array(f1scores)), np.std(np.array(kappas)), np.std(np.array(MCCs))]\n",
    "\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7850f367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold_0</th>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.855697</td>\n",
       "      <td>0.855807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_1</th>\n",
       "      <td>0.923358</td>\n",
       "      <td>0.912604</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>0.829652</td>\n",
       "      <td>0.830993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_2</th>\n",
       "      <td>0.908759</td>\n",
       "      <td>0.913128</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.867725</td>\n",
       "      <td>0.798161</td>\n",
       "      <td>0.798812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_3</th>\n",
       "      <td>0.916058</td>\n",
       "      <td>0.920234</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>0.820657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_4</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.925243</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.843551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_5</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.926874</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.841150</td>\n",
       "      <td>0.841256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_6</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.932029</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.938547</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.839663</td>\n",
       "      <td>0.839771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_7</th>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.916201</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.775528</td>\n",
       "      <td>0.775628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_8</th>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.924772</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.938202</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.840419</td>\n",
       "      <td>0.840526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_9</th>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.959069</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.911424</td>\n",
       "      <td>0.911453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.924803</td>\n",
       "      <td>0.924606</td>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.941611</td>\n",
       "      <td>0.892622</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.835372</td>\n",
       "      <td>0.835846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>0.034029</td>\n",
       "      <td>0.033901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy       AUC  Precision_1  Precision_0  Recall_1  Recall_0  \\\n",
       "Fold_0  0.934307  0.935407     0.915789     0.944134  0.896907  0.954802   \n",
       "Fold_1  0.923358  0.912604     0.922222     0.923913  0.855670  0.960452   \n",
       "Fold_2  0.908759  0.913128     0.891304     0.917582  0.845361  0.943503   \n",
       "Fold_3  0.916058  0.920234     0.855769     0.952941  0.917526  0.915254   \n",
       "Fold_4  0.927007  0.925243     0.873786     0.959064  0.927835  0.926554   \n",
       "Fold_5  0.927007  0.926874     0.888889     0.948571  0.907216  0.937853   \n",
       "Fold_6  0.927007  0.932029     0.905263     0.938547  0.886598  0.949153   \n",
       "Fold_7  0.897810  0.896703     0.863158     0.916201  0.845361  0.926554   \n",
       "Fold_8  0.927007  0.924772     0.887755     0.948864  0.906250  0.938202   \n",
       "Fold_9  0.959707  0.959069     0.947368     0.966292  0.937500  0.971751   \n",
       "Mean    0.924803  0.924606     0.895131     0.941611  0.892622  0.942408   \n",
       "Std     0.015468  0.015616     0.026697     0.016417  0.031875  0.016326   \n",
       "\n",
       "         F1score     Kappa       MCC  \n",
       "Fold_0  0.906250  0.855697  0.855807  \n",
       "Fold_1  0.887701  0.829652  0.830993  \n",
       "Fold_2  0.867725  0.798161  0.798812  \n",
       "Fold_3  0.885572  0.819417  0.820657  \n",
       "Fold_4  0.900000  0.842610  0.843551  \n",
       "Fold_5  0.897959  0.841150  0.841256  \n",
       "Fold_6  0.895833  0.839663  0.839771  \n",
       "Fold_7  0.854167  0.775528  0.775628  \n",
       "Fold_8  0.896907  0.840419  0.840526  \n",
       "Fold_9  0.942408  0.911424  0.911453  \n",
       "Mean    0.893452  0.835372  0.835846  \n",
       "Std     0.022230  0.034029  0.033901  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_metrics.index = ['Fold_0','Fold_1','Fold_2','Fold_3','Fold_4','Fold_5','Fold_6','Fold_7','Fold_8','Fold_9','Mean','Std']\n",
    "fold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3c1b0",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5428955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a81100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOPT:\n",
    "    def __init__(self, data, space):\n",
    "        self.space = space\n",
    "        self.data = data\n",
    "        self.trials = Trials()\n",
    "    \n",
    "    def _split_data(self, fold):\n",
    "        df = self.data\n",
    "        # all columns are features except target and kfold columns\n",
    "        features = [\n",
    "            f for f in df.columns if f not in (\"TARGET\", \"Kfold\")\n",
    "        ]\n",
    "        # get training data using folds\n",
    "        df_train = df[df.Kfold != fold].reset_index(drop=True)\n",
    "        # get validation data using folds\n",
    "        df_valid = df[df.Kfold == fold].reset_index(drop=True)\n",
    "        # get training data\n",
    "        X_train = df_train[features].values\n",
    "        # get validation data\n",
    "        X_test = df_valid[features].values\n",
    "        y_train = df_train.TARGET.values\n",
    "        y_test = df_valid.TARGET.values\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    def _objective(self,space):\n",
    "        clf= DecisionTreeClassifier(**space)\n",
    "        \n",
    "        \n",
    "        accuracies = []\n",
    "        for fold_ in range(10):\n",
    "            X_train, y_train, X_test, y_test = self._split_data(fold_)\n",
    "            evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "        \n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "            pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, pred>0.5)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        final_accuracy = np.mean(np.array(accuracies))\n",
    "        #print (\"SCORE:\", final_accuracy)\n",
    "        return {'loss': -final_accuracy, 'status': STATUS_OK }\n",
    "    \n",
    "    def search_hyperparameters(self):\n",
    "\n",
    "        best_hyperparams = fmin(fn = self._objective,\n",
    "                                space = self.space,\n",
    "                                algo = tpe.suggest,\n",
    "                                max_evals = 500,\n",
    "                                trials = self.trials)\n",
    "        return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31bc92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 10)),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0feebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:46<00:00,  4.67trial/s, best loss: -0.9050827517980803]\n",
      "{'criterion': 0, 'max_depth': 7, 'min_samples_split': 1}\n"
     ]
    }
   ],
   "source": [
    "bayes_opt = BayesianOPT(data, space)\n",
    "best_params = bayes_opt.search_hyperparameters()\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7ecf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 0, 'max_depth': 7, 'min_samples_split': 1}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1908646",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params[\"min_samples_split\"] = 2\n",
    "best_params[\"criterion\"] = \"gini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3066ce",
   "metadata": {},
   "source": [
    "# Train the model with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3312ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold, data, best_hyper_parameters):\n",
    "    # load the full training data with folds\n",
    "    df = data\n",
    "    # all columns are features except target and kfold columns\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"TARGET\", \"Kfold\")\n",
    "    ]\n",
    "    # get training data using folds\n",
    "    df_train = df[df.Kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.Kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    X_train = df_train[features].values\n",
    "    # get validation data\n",
    "    X_valid = df_valid[features].values\n",
    "    # initialize Logistic Regression model\n",
    "    model = DecisionTreeClassifier(**best_params)\n",
    "    y_train = df_train.TARGET.values\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    auc = roc_auc_score(df_valid.TARGET.values, valid_preds)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_true = df_valid.TARGET.values\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    precision_1 = precision_score(y_true,y_pred,pos_label=1)\n",
    "    precision_0 = precision_score(y_true,y_pred,pos_label=0)\n",
    "    recall_1 = recall_score(y_true,y_pred,pos_label=1)\n",
    "    recall_0 = recall_score(y_true,y_pred,pos_label=0)\n",
    "    f1score = f1_score(y_true,y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    MCC = matthews_corrcoef(y_true,y_pred)\n",
    "    print(f\"Fold = {fold}, AUC = {auc}, Accuracy = {accuracy}, \\\n",
    "          Precision_1 = {precision_1}, Precision_0 = {precision_0}\\\n",
    "          Recall_1 = {recall_1}, Recall_0 = {recall_0}, F1Score = {f1score}, kappa = {kappa}, MCC = {MCC}\")\n",
    "    \n",
    "    return auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2a6feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.9463859281262741, Accuracy = 0.9087591240875912,           Precision_1 = 0.9390243902439024, Precision_0 = 0.8958333333333334          Recall_1 = 0.7938144329896907, Recall_0 = 0.9717514124293786, F1Score = 0.8603351955307262, kappa = 0.7932886716156679, MCC = 0.7994614180528328\n",
      "Fold = 1, AUC = 0.8962374046246141, Accuracy = 0.8795620437956204,           Precision_1 = 0.9102564102564102, Precision_0 = 0.8673469387755102          Recall_1 = 0.7319587628865979, Recall_0 = 0.96045197740113, F1Score = 0.8114285714285714, kappa = 0.724480468035834, MCC = 0.7337717019301088\n",
      "Fold = 2, AUC = 0.8922185334032268, Accuracy = 0.8576642335766423,           Precision_1 = 0.8452380952380952, Precision_0 = 0.8631578947368421          Recall_1 = 0.7319587628865979, Recall_0 = 0.9265536723163842, F1Score = 0.7845303867403314, kappa = 0.679079824614091, MCC = 0.6829989520097548\n",
      "Fold = 3, AUC = 0.9264371832954744, Accuracy = 0.8759124087591241,           Precision_1 = 0.8387096774193549, Precision_0 = 0.8950276243093923          Recall_1 = 0.8041237113402062, Recall_0 = 0.9152542372881356, F1Score = 0.8210526315789475, kappa = 0.7261449820683168, MCC = 0.7265221503503666\n",
      "Fold = 4, AUC = 0.9186615411497467, Accuracy = 0.8941605839416058,           Precision_1 = 0.8695652173913043, Precision_0 = 0.9065934065934066          Recall_1 = 0.8247422680412371, Recall_0 = 0.9322033898305084, F1Score = 0.8465608465608465, kappa = 0.7658671695444634, MCC = 0.766491944018289\n",
      "Fold = 5, AUC = 0.9488321975653795, Accuracy = 0.9197080291970803,           Precision_1 = 0.9411764705882353, Precision_0 = 0.91005291005291          Recall_1 = 0.8247422680412371, Recall_0 = 0.9717514124293786, F1Score = 0.879120879120879, kappa = 0.8194020013182336, MCC = 0.8234068388783204\n",
      "Fold = 6, AUC = 0.9103616984099248, Accuracy = 0.8978102189781022,           Precision_1 = 0.8876404494382022, Precision_0 = 0.9027027027027027          Recall_1 = 0.8144329896907216, Recall_0 = 0.943502824858757, F1Score = 0.8494623655913978, kappa = 0.7723307021188202, MCC = 0.7739698836463338\n",
      "Fold = 7, AUC = 0.9397460539344168, Accuracy = 0.8832116788321168,           Precision_1 = 0.8350515463917526, Precision_0 = 0.9096045197740112          Recall_1 = 0.8350515463917526, Recall_0 = 0.9096045197740112, F1Score = 0.8350515463917526, kappa = 0.7446560661657639, MCC = 0.7446560661657639\n",
      "Fold = 8, AUC = 0.947068117977528, Accuracy = 0.916058394160584,           Precision_1 = 0.9101123595505618, Precision_0 = 0.918918918918919          Recall_1 = 0.84375, Recall_0 = 0.9550561797752809, F1Score = 0.8756756756756756, kappa = 0.8124516397833462, MCC = 0.8137784148454805\n",
      "Fold = 9, AUC = 0.9439736346516008, Accuracy = 0.9157509157509157,           Precision_1 = 0.9294117647058824, Precision_0 = 0.9095744680851063          Recall_1 = 0.8229166666666666, Recall_0 = 0.9661016949152542, F1Score = 0.87292817679558, kappa = 0.8102619889402594, MCC = 0.8136187945140734\n",
      "\n",
      "\n",
      "Mean Scores: AUC = 0.9269922293138185,       Accuracy = 0.8948597631079384,       Precision_1 = 0.8906186381223702, Precision_0 = 0.8978812717282134      Recall_1 = 0.8027491408934708, Recall_0 = 0.945223132101822      F1Score = 0.8436146275414709       Kappa = 0.7647963514204796       MCC = 0.7678676164411324\n"
     ]
    }
   ],
   "source": [
    "aucs, accuracies, precisions_1, precisions_0, recalls_1, recalls_0, f1scores, kappas, MCCs = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for fold_ in range(10):\n",
    "    auc, accuracy, precision_1, precision_0, recall_1, recall_0, f1score, kappa, MCC, model = run(fold_, data, best_params)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions_1.append(precision_1)\n",
    "    precisions_0.append(precision_0)\n",
    "    recalls_1.append(recall_1)\n",
    "    recalls_0.append(recall_0)\n",
    "    f1scores.append(f1score)\n",
    "    kappas.append(kappa)\n",
    "    MCCs.append(MCC)\n",
    "    # filename = 'XGBoost_' + str(fold_) + '.pkl'\n",
    "    # joblib.dump(model, filename)\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Scores: AUC = {np.mean(np.array(aucs))}, \\\n",
    "      Accuracy = {np.mean(np.array(accuracies))}, \\\n",
    "      Precision_1 = {np.mean(np.array(precisions_1))}, Precision_0 = {np.mean(np.array(precisions_0))}\\\n",
    "      Recall_1 = {np.mean(np.array(recalls_1))}, Recall_0 = {np.mean(np.array(recalls_0))}\\\n",
    "      F1Score = {np.mean(np.array(f1scores))} \\\n",
    "      Kappa = {np.mean(np.array(kappas))} \\\n",
    "      MCC = {np.mean(np.array(MCCs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1279875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
